{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the following pickle files:  ['2013 PROC 4.8.18.pkl', '2014 PROC 4.8.18.pkl', '2015 PROC 4.8.18.pkl', '2016 PROC 4.8.18.pkl', '2017 PROC 4.8.18.pkl']\n",
      "Loading : 2013 PROC 4.8.18.pkl\n",
      "Loading : 2014 PROC 4.8.18.pkl\n",
      "Loading : 2015 PROC 4.8.18.pkl\n",
      "Loading : 2016 PROC 4.8.18.pkl\n",
      "Loading : 2017 PROC 4.8.18.pkl\n",
      "Finished loading data\n",
      "Total number of rows:  595673\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame as df\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from shibaer import util, features, visualization\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "tprint = lambda s: print('\\n--- %s ---' %s)\n",
    "pprint=lambda i: '%i (%.2f)' %(i,float(i)/len(fraud_events))\n",
    "hour_diff = lambda i:i.total_seconds()/360 if type(i) is not None else i\n",
    "\n",
    "\n",
    "    \n",
    "thumbdrive = 'DATAG'\n",
    "data_dir = 'ER'\n",
    "data = util.load_pickle_files(thumbdrive, data_dir, is_small=False)\n",
    "data_with_targets = features.add_death_columns(data)\n",
    "target_variables = [d for d in data_with_targets.columns if 'T_' in d]\n",
    "target_variables\n",
    "\n",
    "meta_data=util.read_metadata()\n",
    "numeric_cols = meta_data.loc[meta_data.data_type == 'numeric'].index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers from nuerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = util.preprocess_data(data, numeric_cols= numeric_cols, percentiles=[0.001,0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Background variables mortality exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of population with background variable and percent mortality per background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns=['T_is_dead', 'T_release_date', 'T_total_time_hospital',\n",
    "       'T_mortality_ER', 'T_mortality_hospitalization',\n",
    "       'T_mortality_after_hospitalization', 'T_mortality2d', 'T_mortality30d',\n",
    "       'T_mortality60d', 'T_mortality_type']\n",
    "\n",
    "#ndata= util.convert_to_numeric(data, numeric_cols=numeric_cols)\n",
    "print('..')\n",
    "data_with_target_cols=features.add_death_columns(data.head(100))\n",
    "print('..')\n",
    "background_var= 'background_diagnoses'\n",
    "s= data[background_var]\n",
    "bg_diagnosis=df(pd.get_dummies(s.apply(pd.Series).stack()).sum(level=0), index=data.index)\n",
    "print('saving to csv...')\n",
    "bg_diagnosis.to_csv(background_var+'.csv')\n",
    "#(bg_diagnosis.sum()/len(bg_diagnosis)).plot(kind='bar', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('saving to csv...')\n",
    "bg_diagnosis.to_csv(background_var+'head1000.csv')\n",
    "bg_diagnosis.loc[bg_dianosis.sum()>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#background_var= 'background_diagnoses'\n",
    "target_col= 'T_mortality30d'\n",
    "head=50\n",
    "bg_diagnosis_with_target=pd.concat([bg_diagnosis,data_with_target_cols[target_col]],axis=1)\n",
    "\n",
    "target_per_bckg= bg_diagnosis_with_target.groupby(target_col).sum()\n",
    "a.index\n",
    "\n",
    "\n",
    "total_dead_per_bckg= (target_per_bckg.loc[True]).sort_values(ascending=False)\n",
    "top50= total_dead_per_bckg.index[:49] \n",
    "top10= total_dead_per_bckg.index[:9] \n",
    "tprint('top 50 %s for %s (based on total number of deaths):' %(background_var,target_col))\n",
    "print(top50)\n",
    "\n",
    "percent_dead_per_bckg= (target_per_bckg.loc[True]/bg_diagnosis.sum()).loc[total_dead_per_bckg.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_dead_per_bckg.head(head).plot.bar(figsize=(20,10), title='Total number %s per %s' %(target_col, background_var))\n",
    "target_per_bckg.T.loc[total_dead_per_bckg.index].head(head).plot.bar(stacked=True,figsize=(20,5),\n",
    "                                            title='Total %s per %s' %(target_col, background_var))\n",
    "\n",
    "#a.loc[False]/a.loc['True']\n",
    "#.groupby(target_col).sum().T.stackplot(figsize=(20,10))\n",
    "#print(targets)\n",
    "#pd.DataFrame.from_items(zip(l.index, l.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_dead_per_bckg.loc[total_dead_per_bckg.index].head(head).plot.bar(figsize=(20,5), title='Percent %s per %s' %(target_col, background_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pie plot percent of background variable per target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_per_bckg[top10].T.plot(kind='pie', subplots=True,figsize=(15,7),autopct='%1.1f%%',title='Percent %s per %s' %(background_var,target_col))\n",
    "#target_per_bckg[top10].plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of background variable per different target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vars = ['T_mortality2d', 'T_mortality30d','T_mortality60d']\n",
    "bg_diagnosis_with_all_targets=pd.concat([bg_diagnosis,data_with_target_cols[target_vars]],axis=1)\n",
    "'''full_targets = df(columns=target_vars)\n",
    "full_targets_percent = df(columns=target_vars)\n",
    "\n",
    "for t in target_vars:\n",
    "    tt=bg_diagnosis_with_all_targets.groupby(t).sum()\n",
    "    full_targets[t]= tt.T[True]'''\n",
    "    \n",
    "full_targets_percent = full_targets/full_targets.sum()\n",
    "#full_targets_percent.drop(target_vars[1:], inplace=True)\n",
    "#full_targets.drop(target_vars[1:], inplace=True)\n",
    "#print(full_targets)\n",
    "full_targets['total'] = full_targets.sum(axis=1)\n",
    "full_targets.sort_values(by='total',ascending=False,inplace=True)\n",
    "top= full_targets.head(10).index\n",
    "\n",
    "full_targets[target_vars].loc[top].T.plot.bar(stacked=True,figsize=(20,5))#(kind='bar')\n",
    "full_targets_percent[target_vars].loc[top].T.plot(figsize=(20,5))#(kind='bar')\n",
    "full_targets[target_vars].loc[top].plot(kind='pie', subplots=True,figsize=(20,6),autopct='%1.1f%%',\n",
    "                                       title='Percent %s per %s' %(background_var,target_col))\n",
    "print(top)\n",
    "#full_targets[target_vars].loc[top].plot.bar(figsize=(20,5))\n",
    "#full_targets.drop(target_vars,axis=1, inplace=True)\n",
    "\n",
    "#targets_per_bckg= bg_diagnosis_with_all_target.groupby(target_vars).sum()\n",
    "    #print(targets_per_bckg)\n",
    "#['T_mortality_within']\n",
    "#target_per_bckg[top10].T.plot(kind='pie', subplots=True,figsize=(15,7),autopct='%1.1f%%',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization funcs\n",
    "import datetime\n",
    "\n",
    "def stack_plot(data, index_axis, stack_var='age',title=None, ylim=None):\n",
    "    if title is None:\n",
    "        title=stack_var +' by ' + index_axis.dtype\n",
    "    data[stack_var].groupby(index_axis).value_counts().unstack().plot(kind='bar', \n",
    "                                                                      stacked=True, figsize=(20,5), title=title, ylim=ylim)\n",
    "    \n",
    "def plot_with_legend(data,group_var='gender', plot_var='age_on_date',drop_values=[]):\n",
    "    fig, ax = plt.subplots()\n",
    "    groups = data.groupby(group_var)[plot_var]\n",
    "    for k, v in groups:\n",
    "        if k not in drop_values:\n",
    "            v.hist(label=k, alpha=.75, ax=ax, bins = 40)\n",
    "    ax.legend()\n",
    "\n",
    "def plot_time_of_death_from(time_from='admission_date_min', drop_negatives=True, as_time='D', max_period= 1200):\n",
    "    death_delta= (death_data.death_date - death_data[time_from])/np.timedelta64(1,as_time)\n",
    "    if drop_negatives:\n",
    "        death_delta = death_delta.loc[death_delta>0] #remove negative death deltas\n",
    "    death_delta.loc[death_delta<=max_period].hist(bins=100)\n",
    "    #death_days_from_admission.hist()\n",
    "    tprint('Relative time of death after %s (uniqe id_coded) %i-%s '%(time_from,max_period,as_time))\n",
    "    return death_delta\n",
    "\n",
    "def remove_outliers(data, high=0.99, low=0.01):\n",
    "    quant_df = data.quantile([low, high])\n",
    "    print(quant_df)\n",
    "    for name in list(quant_df.columns):\n",
    "        #if quant_df.columns:\n",
    "            data = data[(data[name] >= quant_df.loc[low, name]) & (data[name] < quant_df.loc[high, name])]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_data = data_with_targets.loc[data_with_targets.T_is_dead]\n",
    "print(len(death_data))\n",
    "death_data = death_data.sort_values('admission_date_min').drop_duplicates(subset =['id_coded'], keep='last')\n",
    "\n",
    "print(len(death_data))\n",
    "\n",
    "#dd=plot_time_of_death_from(time_from='T_release_date',max_period=48, as_time='h')\n",
    "data.columns\n",
    "percent_missing= data.count()/len(data)\n",
    "tprint('percent of non-missing values (<90%)')\n",
    "percent_missing.loc[percent_missing<0.9].plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=data_with_targets\n",
    "plot_events_by_time(d.loc[d.T_mortality2d], by_time='admission_date_min',stack_var = 'esi_chameleon')\n",
    "\n",
    "death_data.groupby(['T_mortality2d'])['esi_chameleon'].plot(kind='bar')\n",
    "#death_data.esi_chameleon.value_counts()\n",
    "#death_data.groupby().count()['gender'].plot(kind='bar')\n",
    "#stack_var\n",
    "#death_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols= ['pulse']\n",
    "group_by_col = 'T_is_dead'\n",
    "#clean_data = data_with_targets.loc[datw_with_targets]\\\n",
    "def smart_boxplot(data, filter_var = 'is_hospitalization', remove_outliers = True, group_by_col='T_is_dead', target_cols=['pulse','CPK-MB']):\n",
    "    data=data.copy()\n",
    "    data_col=data\n",
    "    #data.reset_index(inplace=True)\n",
    "    for t in target_cols:     \n",
    "        tcol=data[t]\n",
    "        #tcol=tcol.dropna()\n",
    "        print(tcol.dtype)\n",
    "        if remove_outliers:\n",
    "            tcol= tcol.map({'<10':0})\n",
    "            q=tcol.dropna().astype(float).quantile(0.99)\n",
    "            data_col= data_col.loc[tcol <= q]\n",
    "            data_col.head()\n",
    "            #print(tcol.dtype)\n",
    "            #print((tcol>tcol.quantile(0.99)).value_counts())\n",
    "            #col_ind = remove_outliers(tcol).index\n",
    "             # all columns including t\n",
    "        data_col.loc[data_col[filter_var]].boxplot(by=group_by_col,column=t)\n",
    "        \n",
    "ax = sns.boxplot(x=\"gender\", y=\"pulse\", hue=\"T_is_dead\",\n",
    "                 data=data_with_targets, palette=\"Set3\")\n",
    "#data_with_targets.groupby(group_by_col).describe().T\n",
    "\n",
    "#plot_with_legend(death_data)\n",
    "#plot_with_legend(data_with_targets, group_var='T_is_dead', plot_var='age_on_date',drop_values=[] )\n",
    "#data_col.\n",
    "#smart_boxplot(data_with_targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md= pd.read_csv(os.path.abspath(\"../docs/ER/meta_data.csv\"))\n",
    "md= md.loc[md.is_load==1]\n",
    "\n",
    "data_timestamp_index = 'rss_timestamp'\n",
    "#print(md.head())\n",
    "print('\\n---- ER data categories : ------')\n",
    "print(md.groupby('category').nunique()['column_name'])\n",
    "print('\\n---- When was the  data gathered : ------')\n",
    "print(md.groupby('when (b=before, a=after)').nunique()['column_name'])\n",
    "\n",
    "demographic_cols = md.loc[md.category == 'demographic']['column_name']\\\n",
    "demographic_data = data[demographic_cols]\n",
    "lab_cols = md.loc[md.category == 'Labs']['column_name']\n",
    "tprint('demographic details (all)')\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "\n",
    "def plot_with_legend(data,group_var='gender', plot_var='age_on_date',drop_values=[]):\n",
    "    fig, ax = plt.subplots()\n",
    "    groups = data.groupby(group_var)[plot_var]\n",
    "    for k, v in groups:\n",
    "        if k not in drop_values:\n",
    "            v.hist(label=k, alpha=.75, ax=ax, bins = 40)\n",
    "    ax.legend()\n",
    "#demographic_data.groupby('gender').plot(kind='bar')\n",
    "#[])\n",
    "\n",
    "#demographic_data['gender'].value_counts())\n",
    "print(lab_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## where were people commited?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tprint('commited units:')\n",
    "print(fraud_events.fraud_type.value_counts())    \n",
    "    \n",
    "nunique=fraud_events.nunique()\n",
    "ncount=fraud_events.count()\n",
    "nnunique=pd.concat([ncount,nunique],axis=1)\n",
    "nnunique.columns=[ 'count','unique vals']\n",
    "tprint('Number of values in each fraud label column:')\n",
    "print(nnunique.loc[label_cols].applymap(pprint))#.applymap(pprint))\n",
    "tprint('Number of values in each rss_data column:')\n",
    "print(nnunique.loc[relevant_data_cols].applymap(pprint))\n",
    "\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "death_data=data_with_targets[data_with_targets.T_is_dead==True]\n",
    "death_data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
